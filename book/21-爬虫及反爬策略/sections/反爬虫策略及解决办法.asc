=== 反爬虫策略及解决办法

[format="csv", options="header"]
|===
反爬虫策略, 	解决办法（爬虫）

通过headers进行爬虫检测，例如host，referer，user-agent等字段检测,   	对于基本网页的抓取可以自定义headers，添加headers的数据

基于用户行为的发爬虫：(同一IP短时间内访问的频率),   	使用多个代理ip进行抓取或者设置抓取的频率降低一些

动态网页反爬虫(通过ajax请求数据，或者通过JavaScript生成),   	动态网页的可以模拟ajax请求，将得到的数据进行分析，取出需要的数据；还可以使用selenium + phantomjs，puppeteer + node.js 进行抓取

对部分数据进行加密处理的(数据是乱码),   	对部分数据进行加密的，可以使用selenium进行截图，使用python自带的pytesseract库进行识别，但是比较慢最直接的方法是找到加密的方法进行逆向推理

一次动作，多次请求，并且这些请求会做一些验证操作，例如请求后台会发送后边请求网页需要的cookie，还可以js生成cookie发送给后台进行校验,     	模拟每次重要的请求，将需要的验证参数获取设置到cookie中，解析js生成cookie的规则，然后生成cookie设置到cookie中

对js文件进行加密处理，使js文件难以读懂，在js中设置debug，禁止用户在网页中调试,  	加密的js文件就只有慢慢解析生成验证参数的算法了

针对puppeteer，以及selenium的自动化爬取，校验是否是用webdriver启动,     	将设置浏览器启动是否为webdriver参数值进行修改

每次访问网站，都会进行一次302跳转，服务器发送一个种子（seed），然后跳转界面的js会将这个种子通过一系列算法，生成一个必要的验证参数返回给服务器，并且对这段js进行混淆，避免他人轻易看懂算法,  	方法一（简单粗暴，服务器无法识别是否为webdriver）：使用自动化测试工具（node.js+puppeteer，selelium+webdriver），并且将无头模式的标志设置为false或者删除; 方法二（麻烦，解析需要大量时间）：解析生成验证参数的算法

判断是否使用类似puppeteer的后台浏览器,      使用正常的浏览器完全模拟正常用户，例如使用使用puppeteer直接启动Chrome浏览器
|===



=== 针对反自动化爬虫策略以及解决办法

.1、User-Agent

User-Agent一般用来检测操作系统和用户浏览器，Chrome在Windows下的User-Agent值类似于"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"，

在Linux平台下版本59的Chrome的User-Agent值为"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/59.0.3071.115 Safari/537.36"

通过检测"HeadlessChrome"判断是否为无头浏览器
[source, javascript]
----
if (/HeadlessChrome/.test(window.navigator.userAgent)) {
    console.log("Chrome headless detected");
}
----

.2、Plugins

在Chrome中有默认的plugins，navigator.plugins会返回一个plugins的列表，在无头模式（headless mode）中，这个plugins是空的
[source, javascript]
----
if(navigator.plugins.length == 0) {
    console.log("It may be Chrome headless");
}
----

.3、Languages

在Chrome中，js有两种获取使用语言的参数，navigator.language和navigator.languages，第一个是获取浏览器UI的语言，第二种语言会得到一个字符串列表，然而在无头模式中，navigator.languages返回的是一个空字符串
[source, javascript]
----
if(navigator.languages == "") {
    console.log("Chrome headless detected");
}
----

.4、WebGL

WebGL是执行HTML canvas 3D渲染的API，这个API将会查询图形驱动的vendor和renderer，在Linux平台下的Chrome，图形驱动的vent偶然和renderer为"Google inc."和"Google swiftShader"。

在无头模式中renderer为"Mesa OffScreen",vendor为"Brian Paul"，但并不是所有的无头Chrome的renderer和vendor的值是一样的， "Mesa Offscreen" 和 "Brian Paul"表示无头模式存在。
[source, javascript]
----
var canvas = document.createElement('canvas');
var gl = canvas.getContext('webgl');

var debugInfo = gl.getExtension('WEBGL_debug_renderer_info');
var vendor = gl.getParameter(debugInfo.UNMASKED_VENDOR_WEBGL);
var renderer = gl.getParameter(debugInfo.UNMASKED_RENDERER_WEBGL);

if(vendor == "Brian Paul" && renderer == "Mesa OffScreen") {
    console.log("Chrome headless detected");
}
----

.5、Browser features

在无头模式中，Modernizr 库中没有"hairline"
[source, javascript]
----
if(!Modernizr["hairline"]) {
    console.log("It may be Chrome headless");
}
----

.6、Missing image

在Chrome中图片的长和高依赖于浏览器的显示，不为0，但是在无头模式中，长和高为0，图片的尺寸不会被加载。
[source, javascript]
----
var body = document.getElementsByTagName("body")[0];
var image = document.createElement("img");
image.src = "http://iloveponeydotcom32188.jg";
image.setAttribute("id", "fakeimage");
body.appendChild(image);
image.onerror = function(){
    if(image.width == 0 && image.height == 0) {
        console.log("Chrome headless detected");
    }
}
----
